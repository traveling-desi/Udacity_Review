{\rtf1\ansi\ansicpg1252\cocoartf1504
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\froman\fcharset0 Times-Roman;\f2\fnil\fcharset0 Menlo-Regular;
\f3\fnil\fcharset0 Menlo-Bold;}
{\colortbl;\red255\green255\blue255;\red36\green36\blue36;\red255\green255\blue255;\red0\green0\blue0;
\red255\green255\blue255;\red70\green81\blue90;\red21\green163\blue221;\red35\green46\blue57;\red151\green0\blue126;
\red242\green242\blue242;\red38\green38\blue38;\red20\green0\blue196;\red73\green17\blue135;\red181\green0\blue19;
\red240\green240\blue240;\red0\green0\blue0;\red249\green250\blue251;}
{\*\expandedcolortbl;\csgray\c100000;\cssrgb\c18824\c18824\c18824;\cssrgb\c100000\c100000\c100000;\cssrgb\c0\c0\c0;
\csgray\c100000;\cssrgb\c34510\c39216\c42745;\cssrgb\c784\c70196\c89412;\cssrgb\c18039\c23922\c28627;\cssrgb\c66667\c5098\c56863;
\cssrgb\c96078\c96078\c96078;\cssrgb\c20000\c20000\c20000;\cssrgb\c10980\c0\c81176;\cssrgb\c36078\c14902\c60000;\cssrgb\c76863\c10196\c8627;
\cssrgb\c95294\c95294\c95294;\csgenericrgb\c0\c0\c0;\cssrgb\c98039\c98431\c98824;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}}
\margl1440\margr1440\vieww18380\viewh9740\viewkind0
\deftab720
\pard\pardeftab720\sl640\sa230\partightenfactor0

\f0\fs72 \cf2 \cb3 \expnd0\expndtw0\kerning0
Meets Specifications
\fs40 \
\pard\pardeftab720\sl400\sa300\partightenfactor0

\f1\fs24 \cf4 \cb5 \
\pard\pardeftab720\sl400\sa300\partightenfactor0

\f0\fs28 \cf4 Wow, you are actually generating faces without having seen any of them. Remember your network has seen some faces, but not the faces that it generated. This was an awesome project. You are working on cutting edge applications of GANs.\
Now let's see those faces\
:boy: :girl: :woman: :man: :baby: :older_woman: :older_man: :person_with_blond_hair: :man_with_gua_pi_mao: :man_with_turban: :construction_worker: :cop:
\f1\fs24 \
\pard\tx720\pardeftab720\sl320\partightenfactor0

\f0\fs28 \cf6 \
\
Here are some additinal resources tht you may find interesting:\
\
\pard\tx720\pardeftab720\sl320\partightenfactor0
\cf6 \kerning1\expnd0\expndtw0 * [\expnd0\expndtw0\kerning0
Generative Adversarial Networks Explained with a Classic Spongebob Squarepants Episode](https://medium.com/@awjuliani/generative-adversarial-networks-explained-with-a-classic-spongebob-squarepants-episode-54deab2fce39)\
\kerning1\expnd0\expndtw0 * [\expnd0\expndtw0\kerning0
GitHub - zhangqianhui/AdversarialNetsPapers: The classical papers and codes about generative adversarial nets](https://github.com/zhangqianhui/AdversarialNetsPapers)\
\kerning1\expnd0\expndtw0 * [\expnd0\expndtw0\kerning0
generative-models/GAN at master \'b7 wiseodd/generative-models \'b7 GitHub](https://github.com/wiseodd/generative-models/tree/master/GAN)\
\kerning1\expnd0\expndtw0 * [\expnd0\expndtw0\kerning0
magenta/GAN.md at master \'b7 tensorflow/magenta \'b7 GitHub](https://github.com/tensorflow/magenta/blob/master/magenta/reviews/GAN.md#disadvantages)\
\kerning1\expnd0\expndtw0 * [\expnd0\expndtw0\kerning0
Image Completion with Deep Learning in TensorFlow](http://bamos.github.io/2016/08/09/deep-completion/#using-gz-to-produce-fake-images)\
\kerning1\expnd0\expndtw0 * [\expnd0\expndtw0\kerning0
An introduction to Generative Adversarial Networks (with code in TensorFlow) - AYLIEN](http://blog.aylien.com/introduction-generative-adversarial-networks-code-tensorflow/)\
\kerning1\expnd0\expndtw0 * [\expnd0\expndtw0\kerning0
MNIST Generative Adversarial Model in Keras \'96 O'Shea Research](https://oshearesearch.com/index.php/2016/07/01/mnist-generative-adversarial-model-in-keras/)\
\kerning1\expnd0\expndtw0 * [\expnd0\expndtw0\kerning0
Fantastic GANs and where to find them](http://guimperarnau.com/blog/2017/03/Fantastic-GANs-and-where-to-find-them)\
\kerning1\expnd0\expndtw0 * [\expnd0\expndtw0\kerning0
ARXIV_1](https://arxiv.org/pdf/1406.2661.pdf)\
* [ARXIV_2](https://arxiv.org/pdf/1511.06434v2.pdf)\
* [ARXIV_3](https://arxiv.org/pdf/1606.03498.pdf)\
\
\pard\pardeftab720\sl400\sa300\partightenfactor0
\cf4 \
While I have passed all the sections, there is still a lot of scope for you to improve the quality of notebook and the final results. I hope you will continue to play around with the parameters to see how the results behave.\cf6 \
\pard\tx720\pardeftab720\sl320\partightenfactor0
\cf6 \
\uc0\u8232 {\field{\*\fldinst{HYPERLINK "http://guimperarnau.com/blog/2017/03/Fantastic-GANs-and-where-to-find-them"}}{\fldrslt \cf7 \cb3 http://guimperarnau.com/blog/2017/03/Fantastic-GANs-and-where-to-find-them}}\uc0\u8232 {\field{\*\fldinst{HYPERLINK "https://arxiv.org/pdf/1511.06434.pdf"}}{\fldrslt \cf7 \cb3 https://arxiv.org/pdf/1511.06434.pdf}}\uc0\u8232 {\field{\*\fldinst{HYPERLINK "http://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html"}}{\fldrslt \cf7 \cb3 http://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html}}\uc0\u8232 {\field{\*\fldinst{HYPERLINK "https://medium.com/intuitionmachine/deep-adversarial-learning-is-finally-ready-and-will-radically-change-the-game-f0cfda7b91d3"}}{\fldrslt \cf7 \cb3 https://medium.com/intuitionmachine/deep-adversarial-learning-is-finally-ready-and-will-radically-change-the-game-f0cfda7b91d3}}\uc0\u8232 {\field{\*\fldinst{HYPERLINK "http://web.stanford.edu/class/cs224n/"}}{\fldrslt \cf7 \cb3 http://web.stanford.edu/class/cs224n/}}\uc0\u8232 {\field{\*\fldinst{HYPERLINK "https://github.com/oxford-cs-deepnlp-2017/lectures"}}{\fldrslt \cf7 \cb3 https://github.com/oxford-cs-deepnlp-2017/lectures}}\uc0\u8232 {\field{\*\fldinst{HYPERLINK "https://www.slideshare.net/ThomasDaSilvaPaula/a-very-gentle-introduction-to-generative-adversarial-networks-aka-gans-71614428"}}{\fldrslt \cf7 \cb3 https://www.slideshare.net/ThomasDaSilvaPaula/a-very-gentle-introduction-to-generative-adversarial-networks-aka-gans-71614428}}\uc0\u8232 {\field{\*\fldinst{HYPERLINK "https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f"}}{\fldrslt \cf7 \cb3 https://medium.com/@devnag/generative-adversarial-networks-gans-in-50-lines-of-code-pytorch-e81b79659e3f}}\uc0\u8232 {\field{\*\fldinst{HYPERLINK "http://machinelearningmastery.com/basic-feature-engineering-time-series-data-python/"}}{\fldrslt \cf7 \cb3 http://machinelearningmastery.com/basic-feature-engineering-time-series-data-python/}}\uc0\u8232 {\field{\*\fldinst{HYPERLINK "http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf"}}{\fldrslt \cf7 \cb3 http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf}}\uc0\u8232 {\field{\*\fldinst{HYPERLINK "https://deephunt.in/the-gan-zoo-79597dc8c347"}}{\fldrslt \cf7 \cb3 https://deephunt.in/the-gan-zoo-79597dc8c347}}\uc0\u8232 {\field{\*\fldinst{HYPERLINK "http://cs231n.github.io/transfer-learning/"}}{\fldrslt \cf7 \cb3 http://cs231n.github.io/transfer-learning/}}\uc0\u8232 {\field{\*\fldinst{HYPERLINK "http://ruishu.io/2016/12/27/batchnorm/"}}{\fldrslt \cf7 \cb3 http://ruishu.io/2016/12/27/batchnorm/}}\uc0\u8232 {\field{\*\fldinst{HYPERLINK "http://www.deeplearningbook.org/"}}{\fldrslt \cf7 \cb3 http://www.deeplearningbook.org/}}\
\pard\pardeftab720\sl400\partightenfactor0

\f1\fs24 \cf4 \
\pard\pardeftab720\sl320\partightenfactor0

\f0\fs28 \cf6 \cb3 \
\
\pard\pardeftab720\sl320\partightenfactor0

\b\fs36 \cf8 All the unit tests in project have passed.
\b0\fs28 \cf6 \
\
\pard\pardeftab720\sl400\sa300\partightenfactor0
\cf6 Good job. Unit tests are good way to sanitize your code in chunks. This helps isolate problems to easier to code debug code chunks.\
Always a good practice to write/break your code in small functions to do something focused, granular and easily measured and write unit tests to check that the function. Here are some good attributes of a good function:\
```\
\pard\pardeftab720\sl440\partightenfactor0

\f2\fs26 \cf9 \cb10 short\cf11  code \cf9 size\cf11 \
high efficiency\
low memory footprint\
high reliability\
high generality\
\pard\pardeftab720\sl320\partightenfactor0

\f0\fs28 \cf6 \cb3 ```\
\
\
\pard\pardeftab720\sl320\partightenfactor0

\b\fs36 \cf8 The function discriminator is implemented correctly.
\b0\fs28 \cf6 \
\
\pard\pardeftab720\sl400\sa300\partightenfactor0
\cf6 * You can use a more memory efficient form of leaky ReLu as referenced [here](https://github.com/tensorflow/tensorflow/issues/4079)\
```\
\pard\pardeftab720\sl440\partightenfactor0

\f2\fs26 \cf9 \cb10 def\cf11  \cf12 lrelu\cf13 (x, leak=\cf12 0.2\cf13 , name=\cf14 "lrelu"\cf13 )\cf11 :\
     \cf9 with\cf11  tf.variable_scope(name):\
         f1 = \cf12 0.5\cf11  * (\cf12 1\cf11  + leak)\
         f2 = \cf12 0.5\cf11  * (\cf12 1\cf11  - leak)\
         \cf9 return\cf11  f1 * x + f2 * abs(x))\
```\
\pard\pardeftab720\sl400\sa300\partightenfactor0

\f0\fs28 \cf6 \cb3 * Instead of this\cb5  `
\f2\fs25\fsmilli12600 \cf2 \cb15 flat = tf.reshape(relu3, (-1, 4*4*512))`
\f0\fs28 \cf6 \cb5  \cb3 you can use\cb5  `
\f2\fs25\fsmilli12600 \cf2 \cb15 flat = tf.contrib.layers.flatten(conv4)` 
\f0\fs28 \cf6 \cb3 So that you don't need to remember the shape.\
* Finally, its always a good idea to use a kernel_initializer in the conv2d. You can use\
\pard\pardeftab720\sl400\sa300\partightenfactor0

\f2\fs25\fsmilli12600 \cf2 \cb15 `kernel_initializer=tf.random_normal_initializer(stddev=stddev))`
\f0\fs28 \cf6 \cb3 \
\pard\pardeftab720\sl400\partightenfactor0
\cf6 * Good values for stddev are 0.02 to start with. You can also use the\'a0`
\f2\fs25\fsmilli12600 \cf2 \cb15 xavier_initialize/tf.contrib.layers.xavier_initializer()`
\f0\fs28 \cf6 \cb3 \'a0as the value for the kernel_initializer parameter in\'a0`
\f2\fs25\fsmilli12600 \cf2 \cb15 tf.layers.conv2d`.
\f0\fs28 \cf6 \cb3 \'a0For more see [here](https://www.tensorflow.org/versions/r0.11/api_docs/python/contrib.layers/initializers)\cf7 \
\
\
\pard\pardeftab720\sl320\partightenfactor0

\b\fs36 \cf8 The function generator is implemented correctly.
\fs28 \
\pard\pardeftab720\sl400\partightenfactor0

\b0 \cf7 \
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400\partightenfactor0
\ls1\ilvl0\cf6 \kerning1\expnd0\expndtw0 * \expnd0\expndtw0\kerning0
The same feedback about leaky ReLus as before. You can use the more memory efficient version.\cb5 \uc0\u8232 \
\ls1\ilvl0\cb3 \kerning1\expnd0\expndtw0 *  It\'92s a good idea to use the\expnd0\expndtw0\kerning0
\'a0`
\f2\fs25\fsmilli12600 \cf2 \cb15 tf.contrib.layers.xavier_initializer()`
\f0\fs28 \cf6 \cb3 \'a0in the `conv2d_transpose`. \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400\partightenfactor0
\ls1\ilvl0\cf6 \cb5 \kerning1\expnd0\expndtw0 * Also, as pointed out [here](https://github.com/tensorflow/magenta/blob/master/magenta/reviews/GAN.md#disadvantages) it is important to make the Generator to be more powerful than the Discriminator. So you could try adding one more layer and increasing channel depth at the input. You may get better final results.\expnd0\expndtw0\kerning0
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl400\partightenfactor0
\ls1\ilvl0\cf6 \cb3 \kerning1\expnd0\expndtw0 * \expnd0\expndtw0\kerning0
Also, note that we are using a\'a0`
\f2\fs25\fsmilli12600 \cf2 \cb15 tanh`
\f0\fs28 \cf6 \cb3 \'a0as the final activation in the generator, which means you have to scale the real images to be between -1 and 1 if not done for you already before you start training.\cb5 \uc0\u8232 \
\pard\pardeftab720\sl400\partightenfactor0

\f2\fs25\fsmilli12600 \cf2 \cb15 `out = tf.tanh(logits)`
\f0\fs28 \cf6 \cb3 \
\cf7 \
\
\pard\pardeftab720\sl400\partightenfactor0

\fs36 \cf7 \
\pard\pardeftab720\sl320\partightenfactor0

\b \cf8 The function model_loss is implemented correctly.\
\
\pard\pardeftab720\sl400\sa300\partightenfactor0

\b0\fs28 \cf6 * You can use a smoothing function. Something similar to this  (pay attention to the labels)  :\
\pard\pardeftab720\sl400\sa300\partightenfactor0

\f2\fs25\fsmilli12600 \cf2 \cb15 ```\
d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, labels=tf.ones_like(d_model_real) * np.random.uniform(0.7, 1.2)))\
```\
\pard\pardeftab720\sl400\sa300\partightenfactor0

\f0\fs28 \cf6 \cb3 * You can use a a similar way for the zeros as well.\
\pard\pardeftab720\sl400\sa300\partightenfactor0

\f2\fs25\fsmilli12600 \cf2 \cb15 ```\
d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_model_fake) * np.random.uniform(0.0, 0.3)))\
```\
\pard\pardeftab720\sl400\partightenfactor0

\f0\fs28 \cf6 \cb3 * As mentioned on the\'a0[\cf7 GANHACKs](https://github.com/soumith/ganhacks)\cf6 \'a0it is better to have a number close to 0 and 1 as the labels instead of a strict 0 or 1.\
* The idea is not let the discriminator efficiently learn the one's and thus prevent it from overfitting. We introduce stochasticity in training process an idea similar to adding dropouts.\
\pard\pardeftab720\sl320\partightenfactor0
\cf6 \
\
\pard\pardeftab720\sl320\partightenfactor0

\b\fs36 \cf16 \cb17 The function model_opt is implemented correctly.
\b0\fs28 \cf6 \cb3 \
\
\
# Required\
* Please change\
```\
  \
    #Optimization\
    d_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\
    g_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(g_loss, var_list=g_vars)\
  ```\
to\
```\
    all_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\
    \
    g_update_ops = [var for var in all_update_ops if var.name.startswith('generator')]\
    d_update_ops = [var for var in all_update_ops if var.name.startswith('discriminator')]\
\
    with tf.control_dependencies(d_update_ops):\
        d_train_opt = tf.train.AdamOptimizer(learning_rate,beta1=beta1).minimize(d_loss, var_list=d_vars)\
    with tf.control_dependencies(g_update_ops):\
        g_train_opt = tf.train.AdamOptimizer(learning_rate,beta1=beta1).minimize(g_loss, var_list=g_vars)\
```\
* Why is this required? This is to guarantee that all the variables in the context are updated during training. For a brief explanation see [here](http://ruishu.io/2016/12/27/batchnorm/)\
![Screen Shot 2017-09-05 at 8.21.31 AM.png](https://udacity-reviews-uploads.s3.amazonaws.com/_attachments/44782/1504624915/Screen_Shot_2017-09-05_at_8.21.31_AM.png)\
\
\
\pard\pardeftab720\sl400\sa300\partightenfactor0

\b\fs36 \cf8 The function train is implemented correctly.\cb5 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl320\partightenfactor0
\ls2\ilvl0\cf8 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
It should build the model using\'a0
\f3 \cf2 \cb15 model_inputs
\f0 \cf8 \cb3 ,\'a0
\f3 \cf2 \cb15 model_loss
\f0 \cf8 \cb3 , and\'a0
\f3 \cf2 \cb15 model_opt
\f0 \cf8 \cb3 .\cb5 \
\ls2\ilvl0\cb3 \kerning1\expnd0\expndtw0 {\listtext	\'95	}\expnd0\expndtw0\kerning0
It should show output of the\'a0
\f3 \cf2 \cb15 generator
\f0 \cf8 \cb3 \'a0using the\'a0
\f3 \cf2 \cb15 show_generator_output
\f0 \cf8 \cb3 \'a0function
\fs28 \cb5 \
\pard\pardeftab720\sl400\sa300\partightenfactor0

\b0 \cf6 \cb3 \
* These are the two most important steps in this function to get right to get good results. And you have them correctly done.\
```\cb5 \
\pard\pardeftab720\sl440\partightenfactor0

\f2\fs26 \cf11 \cb10                 batch_images = batch_images * \cf12 2.0\cf11 \
                batch_z = np.random.uniform(-\cf12 1\cf11 , \cf12 1\cf11 , \cf9 size\cf11 =(batch_size, z_dim))\
```\
\pard\pardeftab720\sl320\partightenfactor0

\f0\fs28 \cf6 \cb3 \
\
*******************************\
\
\pard\pardeftab720\sl400\sa300\partightenfactor0
\cf6 * There are two steps that are very important in this function to get correct. You got one right:\
```\
\pard\pardeftab720\sl440\partightenfactor0

\f2\fs26 \cf11 \cb10                 # Sample random noise \cf9 for\cf11  G\
                batch_z = np.random.uniform(-\cf12 1\cf11 , \cf12 1\cf11 , \cf9 size\cf11 =(batch_size, z_dim))\
\pard\pardeftab720\sl400\partightenfactor0

\f0\fs28 \cf6 \cb3 ```\
\
* However, you are missing one. Remember I told you in the generator function that we would need the output of the images (the real images) to be in the range [-1, 1] since the generator outputs the output of `tanh`. Can you print out the max and min values of the images in this function and figure out what range they are in and how you can scale them to the in the range [-1, 1]. That is a critical step. Maybe that is why you are not getting good final results.\
\pard\pardeftab720\sl320\partightenfactor0
\cf6 \
\
\
\
\
\
\pard\pardeftab720\sl320\partightenfactor0

\b\fs36 \cf8 The parameters are set reasonable numbers.
\fs28 \
\pard\pardeftab720\sl320\partightenfactor0

\b0 \cf6 \
\pard\pardeftab720\sl440\partightenfactor0

\f2 \cf11 \cb10 batch_size = 64\
z_dim = 200\
learning_rate = 0.0002\
beta1 = 0.5\
\
\pard\pardeftab720\sl400\sa300\partightenfactor0

\f1 \cf4 \cb5 * Usually a good value for z_dim is 100. Why? That's what I have seen in most papers.\
* You can refer to section 3 of this\'a0[\cf7 paper](https://arxiv.org/pdf/1511.06434v2.pdf)\cf4 \'a0to see that values they used.\
The few most important parameters that you can tune are:\
```\
\pard\pardeftab720\sl440\partightenfactor0

\f2 \cf11 \cb10 batch_size\
learning_rate \
beta1\
```\
\pard\pardeftab720\sl400\sa300\partightenfactor0

\f1 \cf4 \cb5 * Here are the effects of each of them:\
```\
\pard\pardeftab720\sl440\partightenfactor0

\f2 \cf11 \cb10 \'95 Smaller batches usually find a relatively good solution more quickly, as they make a smaller pass through the data before performing an \cf9 update\cf11  however they can be influenced \cf9 by\cf11  most recent examples more heavily.\
\'95 Larger batches can be more stable, \cf9 as\cf11  they \cf9 are\cf11  \cf9 not\cf11  overly influenced \cf9 by\cf11  the most recently seen training examples but take longer \cf9 to\cf11  \cf9 update\cf11  the model parameters.\
\pard\pardeftab720\sl400\sa300\partightenfactor0

\f1 \cf4 \cb5 ```\
* Good choices of batch sizes may also depend on epochs. If you have fewer epochs to train it makes more sense to have smaller batches. This allows weight updates more frequently than if the batches were larger. But try to keep batch sizes as a power of 2. But smaller batches also mean that you will see large changes from batch to batch.\
* The learning rate will determine if the learning is stable or unstable. Most of these networks can become unstable easily and hence a low learning rate is preferred. Your choice of learning rate is fine, but I encourage you to play around with a learning that is one order or two orders larger and one order smaller. What happens to the images?\
\pard\pardeftab720\sl400\partightenfactor0
\cf4 * Finally to the see the effect of beta1 look @ the page for AdamOptimizer. Play around with the values of beta1 using values 0.9, 0.5 and 0.2 and see the effect.\
\pard\pardeftab720\sl320\partightenfactor0

\f0 \cf6 \
\pard\pardeftab720\sl320\partightenfactor0

\b \cf8 \cb3 \
\pard\pardeftab720\sl320\partightenfactor0

\b0 \cf6 \
}